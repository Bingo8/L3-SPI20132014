Cours de langage et compilation
Notes du Suisse

Cours du 10/03/2014
_______________________
Éléments de compilation
'''''''''''''''''''''''
1 Présentation
--------------
1.1 Définitions


* Compilateur
* code source
* code objet

Code source -->[Compilateur]--->code objet

Compiler :
1) Rassembler des documents
2) traduire un prg intelligible par l'hom en code éxécutable
<==> Traducteur "sophistiqué"


* Assembleur /=/ compilateur :
Un assembleur est typiquement un truc prenant du code écrit sous forme très simple (symbolique), et qui le traduit en code objet.
Idem compilateur mais syntaxe simple.
Un compilateur pourra utiliser des structures tels que des arbres, des files, des listes, etc, alors qu'un assembleur, non.
Dans un assembleur, les structures de données internes sont {linéaires, tableaux}
La différence se joue au niveau de la complexité, principalement celles des structures de données gérées.


* Interpréteur
"Compilateur ligne par ligne"
(analogie de la tondeuse à gazon pour un compliateur, passé une fois et une seule sur le code. L'interpréteur, lui, analyse une seule ligne à la fois, produit le code objet correspondant à la ligne analysée, puis passe à la ligne suivante)


------------------------------
1.2 Arbitrage compH / InterprétH

*   Integrated
    Development
    Environnement

Dans les IDE, il est possible de régler la compliation :
CompilH                                       Interpréteur
__________________________________________________________
Runtime                                       Memory size

On règle un curseur pour privilégier soit le temps d'éxécution, soit la taille de la mémoire.

Fondamentalement, le méchanisme d'interprétation (découverte du code) est indispensable. Mais sa lenteur peut devenir gênante avec un grand nombre de ligne d'ou une volonté de le mixer avec un compilateur.

On utilise le coté mise au point de l'interpréteur, puis une fois le code corrigé, le coté vitesse du compilateur devient plus utile.
                 _______________________
                |Mise au point | Vitesse|
                |--------------|--------|
compilateur     |       +      |    -   |
                |--------------|--------|
interpréteur    |       -      |    +   |
                ------------------------

------------------------------------------------
1.3 Compilateur dans les Systèmes d'exploitation

Onion Like

----------------------
Compilateur
----------------------
Edition de Liens
----------------------
Machine Fictive
----------------------
|uP|uP|uP|uP|(micro processeurs)

Les compilateurs sont une couche en amont.

--------------------------------
1.4 Compilateurs de compilateurs

Les "compiler compiler", les compilateurs de compilateurs (CC), sous cette forme

Langage source ====== Langage objet
                 ||
              machine M

Assez souvent, on obtient qqch du style :

       ======
L1 ======||======L3
     ||  M2  ||
     M1      M2


'''''''''''''''''''''''
Tâches d'un compilateur
-----------------------
2.1 Position du prb

            GramR
            AlgéB
code source [O(N³)] code objet
(N symboles)


Comment compiler efficacement?
En faisant un compilateur qui s'éxécute en O(N)  (proportionnel au nbre de ligne)

-----------------------
2.2 Découpage canonique

Le code source est passé dans une première moulinette

Code source    
    ↓
    ↓   -analyse lexicale (20% du temps d'éxécution)
    ↓
chaîne lexicale
    ↓
    ↓   -analyse syntaxique(vérification de la gramR)(30% du temps d'éxécution)
    ↓
arbre syntaxique
    ↓
    ↓   -analyse sémantique(=analyse du sens)(20% du temps d'éxécution)
    ↓
arbre/(DAG) sémantique      Direct Acces Graphe, un graphe sans cycle
    ↓
|->-optimisation
|
|   (30% du temps d'éxécution)
|
|->génération du code

Le compilateur boucle les dernières étapes.

Technique de super compilation -> combinaison de toutes les instructions possible afin de trouver la combinaison idéale.

---------------------------
2.3 Réalité

En réalite, on triche : l'analyse lexicale simplifie certaines choses pour faciliter l'analyse syntaxique. L'arbre généré est également amélioré

Coût de la compilation :
Coût efficacité O(N)
+
coût messages d'erreurs

''''''''''''''''''
3 Analyse lexicale
------------------
3.1 Exemple

code source : Alpha = B ** 2 - Alpha;

Chaîne lexicale : [Identificateur|operateur|Id|operat|nbre|Operat| Identificateur| Délimiteur|FF \
                  [Alpha         | =       |B |  **  |2   |   -  | Alpha         | ;         |FF /
c'est une Pile, ou l'on recherche les identificateurs dans un dico.
Ainsi, Alpha, B(eta) sont stockés dans le dico, et on a en fait un pointeur vers l'élément dans le dico.


1 doublet = 1 lexène = 1 classe + 1 valeur          Alpha 0x2FA [5]


-------------------------------------
3.2 Tâches de ALEX(Analyseur lexical)

1) Sauter l'inutile : les blancs, les caractères de tabulations, les sauts à la ligne, les commentaires, les fins de fichier
2) génère un dico
3) génère une chaîne lexicale
4) On génère des messages d'erreurs.
variantes : classes "erreur"

----------
3.3 Moteur

Algo de principe

Etat <- 0
Rep jsq FF
|    Car <- LireCar()
|    Classe <- ClasseCar(Car)       //renvoie la classe : Identificateurs, nombres, opérateurs
|    Etat <- AEF[Etat, Classe]
frep



_________________________________________________________________________________
Cours du 17/03/2014

-------------------
3.4 Moteur Optimisé

Idx0 <- 0
Idx1 <- Idx0
Etat0 <- 0
Etat <- 0
up jsq Etat = 0
    Car <- LireCar();  //Idx1 est incrémenté
    Classe <-
    Etat <-
    si Etat =
        -1 alors    //Empiler le lexème : Symb <- linSymb(Idx0, Idx1); e <- DicoA; [...] Empiler(Classe Id, e); Idx0 = Idx1;
                    Etat <- AET[Etat0, Classe];
        -2 .....
        ·· .....
        ·· .....
        ·· .....
        -7
    fsi 0 :     //empiler ClassFF; laisser Etat à 0;
Frep


----------------------------
3.5 spécifications du moteur

On crée un fichier de descriptions de lexèmes

Au sens strict, un léxème est au moins un couple (valeur, classe). Par exemple (chaine de caractère, indentificateurs).
exemple : prg -> Idh + nbre + opéra + .... + FF
          Idh -> /[A -Z][A-Z a-z 0-9]*
          |
          |
          |
          FF -> $$
ex : Lex sur UNIX
après compilation, on récupère une fichier objet qui contient l'AEF
Génère en général un AEF 256 colonnes x 250 états, soit 256 Ko.

------------------------
3.6 Compression de l'AEF

·motivations :
    -taille de l'AEF non compressé
    -vitesse d'accès : on accède vite à ce qui est petit (Toujours vrai quelque soit la puissance du processeur).

En comprimant le tableau à environ 25 Ko, on obtiendrai un facteur 3 en vitesse.


·Techinque classique de compression :
    -Superposition de bandes : Obtention d'un gain en compression de 10 à 17.

ex :
          ___________
        1 |1|2|_|_|_|
        2 |_|_|3|4|5|
Etat -> 3 |_|4|_|_|_|
        4 |5|5|_|2|_|
        5 |5|_|_|_|_|

Les bandes correspondent aux lignes.
1) Classer les lignes par densité

2) 5 5 _ 2 _ _ 3 4 5 _ _ _ _ 4 _ _ _     1 2 _ _ _ _
  |         |     |         |           |           |
  l4              l5                    l1
          |         |     |         |
          l2              l3

On repère l'emplacement des lignes.
           _________
           |l1 | 18|
           |l2 | 5 |
Corresp -> |l3 | 13|
           |l4 | 1 |
           |l5 | 9 |
           ---------

Etat <- AEF1[Corresp[Etat] + classe]a


-----------------------
3.7 Gestion des erreurs

·critique : 
    +facile à faire
    +diagnostic pertinent
    -Besogneux : 1 messages d'erreur par case ds l'AEF, ce qui peut faire beaucoup.

    message approprié : "j'attendais " un nombre en base 10 < 10⁶

--------------
3.8 Variations

1) Commentaire intelligent
    Soit bSomme le total des inscrits
    rep
    |
        bSomme

2)    
rep
    si A > 5
frep

si il y a une erreur de compilation (exemple :  sémantique), avec pas de délimiteur style pt virgule, il faut bien repérer le A.
Chaîne lexicale à 6 champs

3) Bidouilles :
    A = -B + C
Qui va repèrer qu'il s'agit d'un '-' unaire et non pas binaire?
On repère un opérateur ('='), on l'empile, puis un second ('-'). On voit qu'il est précédé d'un autre opérateur, on le classe donc comme unaire.

Ce sont des adaptions pour obtenir une GramR algébrique, puisqu'il en faut une impérativement. Elles permettent également de simplifier la gramR, ce qui simplifie l'analyse syntaxique.



··················
Analyse Syntaxique
''''''''''''''
1 Introduction
------------
1.1 Contexte

· pivot d'un compilateur : on commence par écrire la GramR qui servira à l'analyse syntaxique.
Après on fait l'analyse lexicale, puis sémantique, etc.

· à chaque structure on peut associer une gramR. Si on souhaite qu'elle soit efficace, il faut qu'elle soit algébrique (ds le pire des cas, O(N³). On va essayer de s'arranger pour qu'elle tienne en O(N).

· La donnée : une chaîne lexicale (Pour simplifier, il n'y aura pas de classe de léxème erreur. (On pourrait, mais non)) + le Dico(Dico /=/ table des symboles)(On peut tout empiler dans le dico)
· Résultat : 
    -erreur syntaxique
    -Un arbre syntaxique (ou fac similé)

--------
1.2 Dico

Pour des raisons d'efficacité, le Dico est un index et un dictionnaire.
        Index   Dico
(Idh1)  1       1 b
(Idh2)  5       2 S
        8       3 O
                4 M
                5 +
                6 e
                7 4
                8

Le dico est une pile de caractère

L'index permet de vérifier la taille et d'éviter de regarder les caractères dans le dico.

---------
1.3 Modes

Au minimum 2 modes (le mode foncer, et le mode pas foncer)
    -mode vitesse maximale      -> GramR minimale
    -mode gestion des erreurs   -> GramR + riche

Autant pour l'analyse lexicale, gérer les erreurs est pas gênant, ce qui n'est pas le cas de l'analyse syntaxique.

On complète la gramR pour gérer les cas d'erreurs, ce qui ralentit l'éxécution, mais permet de prendre en compte des erreurs fréquentes, par exemple.

------------------------
1.4 Techniques d'analyse

Deux types d'analyses :
    -Analyse descendante (précurseur), bon diagnostic d'erreur, réalisable à la main
    -Analyse ascendente  Très bien pour une compilation rapide, n'a pu être mis en place qu'à partir du moment ou la mémoire centrale > 10 Mo.

Historiquement, on a utilisé l'analyse descendante, l'analyse ascendente prenant beaucoup trop de mémoire (tables trop grandes, donc hors de question).


'''''''''''''''''''
Analyse descendante
-------------------
2.1 Principe

Prg -> Code FF
Code -> Id "+" Nombre

Source 1 :
(Id, A)(opH, +)(Nb, 3)(FF, FF)   :: Ceci est un prg → il y a du code → il y a un Id → Id, A
                                                                     → Il y a un opH → opH, +
                                                                     → Il y a un Nb → Nb, 3
                                                    → Il y a un FF

On peut construire en même temps l'arbre syntaxique.

Source 2 :
(Id, A)(FF, FF)
:: Prg ? → Code attendu → Id attendu → Id, A
                        → opH attendu → !!!!!!! erreur.






!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Absence  : à rattraper
!!!!!!!!!!!!!!!!!!!!!!!!!!!


__________________________________________________________________________
Cours du 31/03

Analyse sémantique :
suite et fin

(but de l'analyse sémantique : voir si les choses ont un sens, et résoudres des problèmes pas encore vus)

---------------------------------
1.3 Arbres d'entrée et de sortie

Quand on fait une analyse syntaxique :

Chaine lexicale
↓
↓       Analyse syntaxique
↓
Arbre Syntaxique

1) Arbre syntaxique
    * analyse par retour arrière lent
        T -> X + Y + Z et aucun critère pour choisir X, Y ou Z
        X(↑x) -> A(↑a)B(↑b) construire(x, a, b)
    * analyse LL(1) par exemple
        T -> aX +bY + cZ
        X -> A(↑a)B(↑b) construire(x, a, b)         L'arbre est toujours contruit à bon escient

    * variant : pile du parcours syntaxique (racine-filsgauche-filsdroit)
    L'arbre est remplacé par une pile qui décrit le parcours canonique direct dans l'arbre

    * prb majeur :  1 arbre syntaxique contient plein de choses inutiles (exemple d'une expression contenant une somme et un produit contenant à leurs tour plein de trucs, et ainsi de suite, pour arriver au bout du compte au nbre 2. 


2) ce qui a du sens ds l'arbre sémantique, c'est uniquement ce qui est indispensable pour générer du code
ex : A <- B + C
   on veut générer : R1 <- B
                     R2 <- C
                     R3 <- R1 + R2
                     A <- R3
=> Arbre sémantique utile.

* Bilan : la solution la plus économique, c'est :
    -une gramR attribuée
    -Des décorations supplémentaires dédiées à la sémantique, essentiellement pour dire ce qu'il faut conserver ds l'arbre
 
exemple : conditionnelle -> "if" exp bool "alors" option {"sinon" alternative }"fsi";
                        (C)             (E)             (O)                 (A)

                        cons(C, O, E, A) construction brute arbre ds un seul mode
exemple 2 :
    Appel -> NomRoutine(R) · Liste Param(LP) . OKParam(P). générerAppel(P, R)

OKParam permet signaler au compilateur qu'on privilégie le contenu à la vitesse.

En mettant de la couleur, en fonction du mode, certaines choses, certaines routines auront une couleur particulière.

Grace à la couleur, et d'autres d'acorations, on élimine en partie ce dont on a pas besoin.


exemple 3 :
    rep ttq B < 10
        si A > 5
            b <- 2
        si A < 7
            B++
    frep

1.4 Les DAG
(Direct Access Graph, les graphes sans cycles)

Obtenu en compilation en mettant en factorisant les sous arbres identiques

exemple
T[c] <- T[c] + 2
    
        ←
     /     \
    [       +
   / \     / \
  Id Id   [   Nb
  |  |   / \   |
  T  C  Id  Id 2
        |   |
        T   C

Avec un DAG
     ←
   /  \
  [ <--+
 / \    |
Id  Id  Nb
|   |   |
T   C   [

* détection de sous arbres identiques.


1.5 critique des DAG
    + en général, sur les lgges de haut nivaux
    + simplicité algébrique
    + demande de code objet compact
    - inefficaces sur des portions trop petites
    - le père d'un noeud n'est plus unique.


SCHPUNZZZZZZZZZZZZZZZ!

''''''''''''''''
2 Pb sémantiques
----------------
2.1 sémantiques des 4 opérateurs

Tous les langgages d'assemblage ont des informations absolues et des information translatables.

A signifie Absolu et T translatable
Ces tableaux indiquent ce que génère les opérateurs, qu'est ce qui cause des erreurs (X).

+|A|T
-----
A|A|T
-----
T|T|X

-|A|T
-----
A|A|X
-----
T|T|A

*|A|T
-----
A|A|X
-----
T|X|X

/|A|T
-----
A|A|X
-----
T|X|X


=> La séparation entre code correct sémantiquement et code incorrect est délicate et un peu arbitraire.

bilan : si on peut accepter une instruction, accpetons là, sauf si c'est "très probablement" faux.

------------------------------------
2.2 type et forçage d'une expression

*entiers et réels.

eA <- eB + eC           entier + entier = entier (et même chose avec les réels)
eB <- eC + rD           soit erreur, soit conversion implicite, d'entier vers réel ou vice versa, dépend du langage.
rD <- eB * 1.0          conversion implicte en réel.
eB <- (eB + rD) modulo 5    soit erreur, soit conversion, soit mod etendu aux réels.

* en règle générale un compilateur zélé vérifie à la compilation le type des expressions qui sont des combinaisons de constantes.

--------------------------------------
2.3 contrôle des paramètres de routine

Routine -> NomRoutine  ListeParam(p) OkParam(p)

=> on peut vérifier que le nbre de paramètres d'un appel de routine coincide avec le nbre de param d'une déclaration de routine.
On ne peut pas toujours confronter le type des paramètres de l'appel avec celui de la déclaration.
La limite est atteinte avec le type union.
