----Graphes-----
Made In Switzerland
Libre à tous de faire une belle version pdf!!
Cours du 22/10/2013


________________________
2.2 Limites d'efficacité
------------------------

(1)Seuil de Sasa..... /Version sans tas
(2)Initialisation du tas?

->initialiser une fois pour toute, complètement
->initialiser petit à petit, en ajoutant les éléments au fur et à mesure

La première version n'est pas idéale, l'autre étant plus efficace jusqu'a 30%

constante cachée :  f(n) = a n² +bn + alog(n)
    ->a est la constante cachée.
_____________
3 Distanciers
-------------
3.1 Pb
-------

G(S, H)
-On veut calculer les chemins les + courts de sommets à sommets.

-Circuits? acceptés? (attention aux circuits négatifs ou positifs)
                        >0   A-(2)->B-(3)->C-(4)->A
                        
                        <0  A-(2)->B-(3)->C-(-10)->A
_________________
3.2 Algo de Floyd
-----------------
-Pas de circuits négatifs
-principe : x° de matrice

Soit trois Sommets I, J et K. On cherche à verifier quel est le chemin le plus court de I à J

    rep pr K de 1 à S
        rep pour I de 1 à S
            rep pour J de 1 à S
                si d(I, J) > d(I, K) + d (K, J)         //Si la distance directe [IJ] est plus grande que [IK]+[KJ]



     -> A > B (avec A ~= d(I, J) et B ~= d(I, K)+d(K, J)
        ->si B a un infini, ne rien faire

        Sinon si A infini, Actualiser d(I, J)
            sinon actualise d(I, J) si c'est mieux

Complexité en O(S³)
_____________________________
4 Variantes sur les distances
-----------------------------
4.1 Chemin le + long
--------------------
(figure n)

Algo possible si
-pas de circuits
-graphe orienté

Comment fais-t'on ?
On remplace chaque distance par son opposé, puis Dijkstra, puis complémenter les résultats

*****Remarque*****
La detection de circuit est exécutée avant (dans le cas général, s'il s'agit d'un graphe que vous ne connaissez pas)

______________________
4.2 Chemin le + fiable
----------------------

cyndinique = études des risque matériels.

On attache à chaque arc ou arrête un pourcentage de risque, ou une fiabilité /!\ la fiabilité est l'inverse du risque

ex : A - 50% -> B - 25% -> C
Il faut calculer le produit des fiabilité (des pourcentages)

A - alpha -> B - Beta -> C

1°)alpha = log(50%)
Beta = log(25%)
En prenant le log, on est ramené à des additions. Car log(x) + log(y) = log(xy)

2°)=>Dijkstra, normal avec addition

3°)On réduit les résultats en passant aux exponentielles (puissance de 2)

ex : Graphe G
A - 8 -> B - 4 -> C - 8 -> D

Graphe G'
A'- 3 -> B'- 2 -> C'- 3 -> D'

Dijkstra -> d(A', D') = 8
ce qui donne 2⁸ = 256
Bizarre, mais le passage au log était plus facile

____________________________
4.3 Chemins moyen le + court
----------------------------

soit A - 2 ->B - 4 ->C - 3 ->D

On cherche la distance la plus courte moyennée
Ainsi, de A à B, c'est 2. De A en C, on a 6/2 = 3. de A en D, on a 9/3 = 3

______________________
5 Composantes connexes
----------------------
5.1 Connexité "faible"
---------------------

Définition : un grapheG=(S, A)  est connexe s'il existe toujours au moins un chemin entre deux sommets quelconques de G (non-orienté ou transformé en non-orienté, c'est à dire qu'on se fiche des flèches)

ainsi, A -> B <- C est un graphe connexe.

l'algo utilise ici un parcours en profondeur d'abord. Il faut une exploration.

-Pb général : Attribuer à chaque sommet le n° de sa composante connexe.

CC[]<-0    ##N° de composante connexe attaché à chaque sommet
nCC <-0
rep
    X<- Unsommet tel que CC[X] = 0      ##X un sommet quelconque non marqué
    nCC++
    CC[x]<-nCC
    Explorer G depuis X
        pour tout Y rencontré
            faire CC[Y]=nCC
fin rep

___________________
5.2 Connexité forte
-------------------

Il est indispensable qu'il s'agisse d'un Graphe orienté
Définition : Un graphe est fortement connexe s'il existe pour toute paire de (X, Y) de sommet 1 chemin de X à Y et vice versa (de Y à X).

Algo (simple mais lent, on sait faire mieux)

CFC[]<- O
nCFC<- 0
rep
    X<- 1 Sommet tel que CFC[X] = 0
    nCFC ++
    explorer dans G depuis X (memoriser les sommets rencontrés);
    explorer dans H depuis X |  ## H est le graphe inverse de G-> on inverse le sens des flèches
                             ->(mémoriser les sommets rencontrés)
    effectuer CFC[Y]<- nCFC si Y a été mémorisé dans G et dans H
finrep

___________________
6 Graphes biparties
-------------------
6.1 Pb
------

On veut savoir si un graphe est biparti

Un graphe est biparti s'il est 2-colorable-> On colorie chaque sommet, et chaque sommet ne doit pas être de la même couleur que ses voisis (sommets adjacents)
Un graphe est biparti si et seulement s'il ne comporte aucun cycle impair

________
6.2 Algo
--------
________________
7 Ordonnencement
----------------
7.1 Vocabulaire
---------------

Les Arcs du graphe correspondent à des tâches
Les Ommets sont des états

ex: D - 15j -> F   Il faut 15 jours à partir du Début pour terminer les Fondations

Date au plus tot/tard -> Marge : chemin critique

Ainsi A - 2j -> B
      A - 1j -> C
      C - 4j -> B

La date au plus tot est de cinq jours  : C'est le chemin le plus long depuis le départ.
La date au plus tard est le chemin le plus long depuis l'arrivée retranché au temps total.
Le chemin critique est le chemin sur lequel une augmentation du temps rallogerait la durée totale

________
7.2 Algo
--------

On introduit deux sommets, Départ et Arrivée dans G.
On relie tous les sommets sans prédecesseur à D avec une durée nulle, et tous les sommets sans Successeurs à A avec une durée nulle.
On chemine en mode chemin le + long dans G(comme vu précedemment).
On obtien Dtot(X) La date au + tot de A qui donne la durée des travaux.
On chemine dans le graphe inverse de G. SDtard est la durée obtenue depuis A.
La date au plus tard d'accomplissement des tous les travaux pour valider X est Dtot(A) - Dtard(A)

La marge critique de chaque sommet est la différence entre la date au plus tot et la date au plus tard

le(s) chemin(s) critique(s) est le chemin qui passe par tous les sommets de marge nulle.







___________________________________________________________________________________________
Cours du 05/11/2013
__________________
Flots et couplages
------------------

Intro :
ça permet d'optimiser les choses.

1 Flots
1.1 Définition
G est valué par des capacités
    -maximale Cij  i -- > ---j   (considéré comme facile)
    -minimale                    (considéré comme difficile)
}polynomiale

    -encadrement min/max

    -idem avec coût d'utilisation à chaque arc

-Source : 5 -- 1 -->_-- 2 -->_      (sink)
           \-- 3 -->_ -- 2 /
-Puit (trap)

capacité résiduelle : capacité max d'un arc, moins ce qui a été consommé précedemment.

1.2 trsformat° des graphes

*contrainte intermédiaire*

(S) -- 4--> (A.3) -- 7 --> (B) --2 --> (T)
S = source, T = trap (puits).

A possède une contrainte limitant le débit à 3.
Si l'on rajoute un sommet entre A et A et un arc entre A et T, on peut modéliser A en deux sommets : une entrée et une sortie, avec une capacité de 3 entre les deux.

*Arête -> arc :
A --- B == A -->-- B
             \-<-/

1.3 Exemple : 


-> ce qu'il faut retenir : les flots s'ajoutent algèbriquement.


1.4 Algo de Flots max et cap max
(note :C() capacité,  Cr()capacité résiduelle et o⁺ flux)


F = 0 (flot max)
rep jsq impossibilité (c = 0)
    c <- chaîne améliorante
    si c > 0
        o⁺ = in | des capac résiduelles sur la chaîne
        pour chaque arc ij  sur la chaîne
        Cr(ij) = Cr(ij) - o⁺ si pris ds le sens de l'arc
        ou Cr(ij) = Cr(ij) + o⁺ si pris ds l'autre sens.
    fs
frep

chaîne améliorante = chemin de S à T tel que pour chaque arc ij, 
Cr(ij) > 0 ds le sens normal 
ou 
C(ij)-Cr(ij)  > 0 ds le sens inverse

Utiliser la recherche d'un plus court chemin(ex Dijkstra)

1.5 Max Flow = Min Cut

L'algo donne un flot optimum qui est le flot max.
Justificat° : considérer les coupes

1.6 Complexité algorithmique

Chemin le plus court : O(S³) avec Dijkstra standard et graphe dense
=> contribution de 1 ds le pire cas
=> itération au pire de "capamax" fois.
=>O(S³ . "capamax")


___________
2 Couplages
-----------
Un couplage est un appareillement de sommets
On cherche un nombre maximal de couples <=> un couplage maximal <=> 1 couplage de cardinal maximal




_____________________________________________________________
                   Les grammaires
                   --------------
______________
1 définitions :
--------------
1.1 Alphabet et mot:
*Un alphabet est un ensemble de lettre minuscule (sans accents). ensemble fini.
*A = {a, b}
*un mot est une suite ordonnée de lettres de l'alphabet éventuellement vide. 
m1 = ab   |m1| = 2
m2 = ba
m3 = a⁵b = aaaaab  |m3| = 6

/!\ mot vide noté 1, |1|= 0

a.1.1.b.1.a.1 = aba
|a.1.1.b.1.A.1| = 3

____________
1.2 Facteurs
------------

1 facteur = 1 partie de mot (éventuellement vide) = 1 sous chaine (prélèvement ds le mot d'une série de lettre consécutive)

ex : m1 = a³ba  alors a²b est un facteur de m1
un facteur gauche  ex a² est un facteur gauche de m1
"        " droit
"        " strict  est un facteur non vide

ex : 
m2 = a²b     =aab
m3 = ab²     =abb
m4 = a²b⁵ab² =aabbbbbabb

m2 est un facteur gauche de m4 et m3 est un facteur droit de m4.


****************************************************************
cours du 15/11/2013

_____________________
1.3 Opérateurs * et +
---------------------

alphabet A = {a, b}
opérateur * :
A* = {1} U A U A² U A² U .....
   = {a+b} si A = {a, b}



. -> opérande de concaténation => ab == a.b
A.A == (a+b).(a+b) = a.a +a.b + b.a + b.b = a² + ab +b²

E = {1, a, a², ad²}
E* =

Opérateur + :
A+ = A U A² U A³ U....

E = {1, a, a²}
E+ = E (1 + a +a²) + E²(1 +a + a² + a³ + a⁴) +....

_____________
2 Vocabulaire
-------------

2.1 Définition

*Ensemble de majuscules, réservé aux ensembles de mots
ex : S = {a, a², ba⁵}
1 seule majuscule

________________________________________
2.2 Opérations sur les ensembles de mots
----------------------------------------

\0 -> représente un ensemble vide (ce n'est pas le mot vide!!!!!!!!!!!!!!!!)

ex : a²b.1 = a²b

E = {a, a²b, ab² }
F = {b³, b⁵}

U = E + E.F + E.\0.F + \0.\O
= {a, a²b, ab², ab³, ab⁵, a²bb³, a²bb⁵, ab²b³, ab²b⁵}

____________
3 Grammaires
---------------
3.1 Définitions

Grammaires : ensemble de règles/productions

<V, A, P, ...> au minimum
Vocabulaire
Alphabet
Productions ou règles

ex : 
     S -> ab
     S -> T {b, abab}
     T -> aU
     U -> abT
     U -> b
Ce sont des productions

S = {ab, abab}

      S
     /  \
    ab   T
      /   \
     a     U
         /   \
        U2    U1
       /  \   |
      ab   T  b

U -> abT + b
U -> aba.u + ab
     (aba)*. ab

production au sens strict : S -> m  avec m appartient à A*
                              1 seul terme, 1 règle

production au sens large S ->m1 + m2

_________________________
3.2 Classes de grammaires
-------------------------

*classe de langage
(((((Expressions régulière) Automate à pile) Grammaire Algébrique)sensible au contexte)Problèmes récursifs)
                                                                                                    ^
                                                                                                    |
                                                                                        limite pour les ordinateurs
Nous allons oublier les problèmes récursifs et les langages sensibles au contexte

*Classes de Grammaires

1)Grammaires linéaires, régulières, rationnelles, reconnaissable (c'est la même chose)
     S    ------------>         aU
     S    ------------>         1
  (1terme à gauche)

2)Grammaires algébriques(Context Free Grammar)
1 terme à gauche, qui est toujours une majuscule, et a droite, une collection de majuscule et/ou de minuscule
S ->aUbV

règle algébrique de la forme : (A : Alphabet et V : Vocabulaire, g terme gauche et td terme droit)
tg -> td  avec tg € à V
               td € à (A U V)*
Une grammaire algébrique reconnait les expressions correctement parenthèsés.

3)Grammaire sensibles au contexte (Context Sensitive Grammar)
le terme a gauche € (a U V)*V(a U V)* -> au moins une majuscule à gauche

4)grammaires récursives
le terme gauche est non vide
     ex :S -> aT + bU
          atU ->b aSSb + c
          acbb -> ab² -> FAUX

____________
3.3 Exemple
------------

S -> aT + bU
T -> abT +1
U -> aUb + a



________________________________________________________________________________________________
Cours du 22/11/2013

____________________
Grammaires Linéaires
--------------------
1 Définitions et propriétés
****************************
1.1 Linéaire à droite

Soit une grammaire Gd = <V, A, P>
Vocabulaire (majuscules)
Alphabet (minuscules)
Productions réduites à soit P ->aT
                       soit P ->1

Un mot est reconnu, si, partant de S(état initial), on atteint un état final (que des minuscules dans le mot).

L(G) = {m € A*, S -*->m}           =>Langage de G
A = {a, b}                         =>Alphabet
A* = {1, a, b, aa, ab, a³, ......}

S - - - > m
_____________________
1.2 Linéaire à gauche
S -> Tb
S -> 1
(la majuscule est à gauche, contrairement au paragraphe d'au dessus)
_________________
1.3 Lien avec AEF

AEF = 1 graphe
     1 sommet = 1 état de l'AEF
     chaque arc représente 1 transistion entre 2 états, franchie si la lettre attaché à l'arc est reconnue
-> Automate d'Etat Fini

S -a-> T -b-> U
S -> aT
T -> bU
U -> 1
_____
2 AEF
-----
2.1 Définitions

Un AEF <=> Â =< A, E, I, F, T>
Alphabet
Etat = corresponds à un sommet dans le graphe
etats Initiaux (I€E)
etats Finaux
Transition -> arc dans 1 graphe
     Une transition, c'est un triplet (alpha, l, w)
     alpha = etat de départ
     l = lettre sur l'arc issus de T
     w = etat d'arrivée

ex (précédent)
     A = {a, b,}
     E = {S, T, U}
     I = {S}
     F = {U}
     T = {(S, a, T), (T, b, U)}
Un mot est reconnu ssi il existe un etat initial i et un etat final f et une suite de transitions delta tel que:
delta(i, m) = f=> m est reconnu

/!\/!\/!\/!\/!\/!\/!\/!\/!\/!\/!\/!\/!\/!\/!\/!\
J'utilise la lettre Â au lieu d'un A majuscule anglais (script)
\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/\¡/

*Un automate complet : Âc:
Pour tout état e et toute lettre l de A, il existe une transistion delta(e, l)

Ainsi, pour l'exemple précédent
S -a-> T -b-> U
on complète chaque état pour chaque lettre
S -a-> T -b-> U =>
 \     |     /
  b    a    a,b
   \   |   /
    v  v  v
     ( þ )
     |   ^
     -a,b|

*Automate déterministe Âd
Il existe un seul etat initial et pour tout état e et tout lettre l, il existe une seule transition au plus(pas plus de une)
______________
2.1 Complétude

méthode :
1)Ajouter 1 trappe : etat(þ) bottom 
/!\/!\/!\/!\/!\ j'utilise þ ici au lieu d'un T à l'envers
2)en faire une trappe  flèche sur lui même avec A  ->   (þ)
3)pour tout etat e, si une lettre l ne part pas de e, ajouter la transisition (e, l, þ)
___________________
2.3 Déterminisation

1) Tabuler l'AEF Âd
2) Générer les super états
3) Déduire l'AEF Âd

1°           a      b
     ->S||   U   || /
     ->T||   V   || W
     <=U||   /   || W
       V||  U V  || /
     <=W||   W   || /

2°           a       b
{S, T}  || {U,V} || {W}
{U, V}  || {U,V} || {W}
{W}     ||  {W}  || /

3°(je fais pas les dessins)
(en tout cas, pas les trop compliqués)
____________
2.4 Critique

*Complétude :  (E ds AEF == S ds Graphes)
     -Complexité O(1) 1° (þ)
                 O(|A|) 2° (->)
                 O(S|A|) 3°
                 au final, on a O(S) car |A| est constant
*Déterminisat°
     -Difficile sans ordinateur
     -Complexité : le nbre de super état croît exponentiellement => O(2^S) si S est le nbre de d'etat
_________________
3 Complementation
-----------------
3.1 Definition

Â
L(Â) = {m€A, ð(i, m) €F)
L(Ä) = {m€A*, m € L(Â)}
/!\/!\/!\ J'utilise Ä au lieu de Â barre
___________
3.2 Méthode

(eeeeeeeeeeeeeeeet j'ai pas suivi)

(mais apparemment, il faut rendre l'automate déterministe et complet)

Deux solutions
1°) Â -> Âd ->Âdc ->Ädc
2°) â -> Âc ->Âcd ->Âcd

On montre que la complétude est conservée par la déterminisation, et vice versa.
___________
3.3 Exemple
(comme ci dessus, le graphe est compliqué, je dessine pas)
(Il faut faire de la trappe une sortie)

________________________________
4 Autres opérateurs ensemblistes
--------------------------------
4.1 Ou logique

On a Â1 et Â2, on cherche Â1U2
L(Â1U2) ) {m€A*, m €L(Â1)}
              ou m €L(Â2)}

Il suffit de juxtaposer Â1 et Â2 en veillant à ce que les numeros d'etats soient différents
______________
4.2 Et Logique

L(Â1n2) = {m€A*, m €L(Â1) et m € L(Â2)}
il faut fabriquer L(Â1) U L(Â2)

_________________
5 Etoile et point
-----------------
L(Â*) = {1} U L(Â) U L(Â).L(Â) + ......



Cours du 02/12/2013
_______________________________
Grammaires algébriques strictes
______________________________
1 Définitions
-------------
1.1 Gramr algébrique

<V, A, P, S>
Vocabulaire    (majuscules)
Alphabet       (minuscules)
Productions    (aucune parenthèse, aucun exposant sauf constante)
Start          c'est le point de départ de la gramR. S € V (c'est un élément du vocabulaire). Il a un sens qui est précis

Dans une gramR algébrique, il y au moins forcément un S en tête d'une production
________________
1.2 Substitution
G une gramR algébrique
m € A* 1 mot

m engendré par G?
Oui, ssi en partant de S, on peut obtenir m
S -*-> m  (-*-> signifiant nbre quelconque fini de règles)

toute règle de G est de la forme
élément de V "-->" mot élargi

mot élargi : mélange de majuscule et de minuscule éventuellement vide
V × (A U V)*
Un seul terme (une majuscule) à gauche de la flèche
substituer, c'est remplacer une majuscule située en membre gauche d'une règle par son membre droit

ex : G :{
     S ->S aSb (1)
     S -> T    (2)
     T -> aTT  (3)
     T -> b    (4)
S -(1)-> aSb -(1)-> a²Sb² -(2)-> a²Tb² -(3)-> a³TTb² -(4) -> a³bTb² -(4) -> a³bbb² = a³b⁴
dc S -*-> a³b⁴

____________________
1.3 Langage engendré

*Langage elargi
L(G) = {m € (AUV)*, S-*->m}   <-Majuscules et|ou minuscule

*Langage engendré
L(G) = {m € A*, s -*-> m}     <-Que des minuscules
_______________________
1.4 Arbre de dérivation

     S         ->membre de gauche
    /|\        
   a S b       ->membre droit
    /|\
   a S b
     |
     S
     |
     T
    /|\
   a T T
     | |
     b b
     
_________________
1.5 GramR ambigue

1 gramR est ambigue s'il existe au moins au mot s'il existe au moins 1 mot de G tel que il existe au moins deux suites de dérivations qui mènent de S à m
exemple : m = a³b⁴

Dire si 1 une gramR algébrique est ambigue est indécidable
i.e le temps necessaire pr le savoir est infini ds le cas général
_______________________
2 Propriétés et limites
-----------------------
2.1 Propriété :

Les gramR engendrent :
-Les langages linéaires (AEF)
-Les langages parenthésés

L(G) = {m € A*, m = (a^n)(b^n)(c^n)} non algébrique
L(G) peut etre engendré par une GramR sensible au contexte.
___________
2.2 Limites

S -> TF
T -> aTbC
CF -> Fc
Cb -> bc
F -> 1
____________________________________
3 Trsformation des GramR algébriques
----------------------
3.1 Récursive (Gauche)

Pb : S-> Sa + b
(idem sans récursivité à gauche)

L(G) = ba*

cas général de récursivité à gauche

S -> Sm1 + Sm2 + Smp + ... + w1 +....+ wq
S -> w1S' + w2S' + ... + wqS' + w1 + w2 + ... + wq
S' -> m1S + m2S + ... mpS + m1 + m2 + ... + mp

en appliquant ce procédé sur n règles qui commencent par n majuscules distinctes, on supprime leurs récursivité à gauche, on aura généré 2 n règles au sens large

*Critique*
+ automatisation
+ utile pour une ou deux récursivité à gauche
-défigure la gramR d'origine
_____________________
3.2 Chomsky (pr info)

principe : {S -> aSTbU + abT + a
            T -> aTT +b
            U -> Ub +1 }

            S -> aQ
            Q -> SR      \
            R -> TP       <-> S -> aSTbU
            P -> bU      /

noms | tableau a deux colonnes
S    |
Q    |
R    |
P    |

___________________
3.3 Formes normales
voir cours d'après
__________________________________
4 Complexité des gramR algébriques
---------------------------------
4.1exemple : G= 
S -> D
S -> D.D + 1

D décrit une forme
D0 : D -> 1
D1 : D -> 

par recurence, on a :
Dn -> D(n-1).D(n-1) +1
     pforme  qformes
D(n) = nbre de forme
D(n) = p.q + 1
<= D(n-1)² +1
ds le pire cas
D(n) = D(n-1)² +1

On note que D(n) croit plus vite que 2⁽²^n⁾

4.2 Conclusion :
- Complexté exponentielle
+ formalisme puissant
+ langage déclaratif
_________________
Gramaires propres
-----------------
1 Vue d'ensemble
****************

-nettoyage de la GramR <=> enlever ce qui est manifestement inutile

-élimination des mots vides



*******************
Cours du 10/12/2013
*******************

__________________
Grammaires Propres
---------------------------
1 Préréduction et reduction
=============
1.1 Réduction

*Objectif : ne conserver que les regles qui "produisent" qqch
i.e qui rendent au moins un élément du vocabulaire productif

ex : 
S -> T + U
U -> a
T -> V
Grâce à la regle U-> a L(U) non vide

*Algo ascendant :

!!!!!!!!Un == Union!!!!!!!!!!!!!

P0 = A

rep jsq invariance
     
     Pi = Pi -1 Un{U € V, U -> n et n ne contient que des éléments de  Pi-1 ou le mot vide, n € (Pi -1)*}

frep

*ex : 
S -> aT + Ub + P + Q
P -> aT + b
U -> 1
T -> Ua
Q -> RQ + bQ

 P0  ||   P0 + ↓ = P1  ||     P1 + ↓ = P2
a, b || P        U     || T        S
     || P -> b²  U -> 1|| T -> Ua  S -> Ub
{ P0 }
{         P1           }
{                 P2                     }

P3 = P2 =Pfinal
=> L(Q) = ø
=>Toute regle avec Q est superflue


*nettoyage : termine l'algorithme
     enlever tte regle dont le membre gauche n'est pas dans Pfinal
     et tout membre droit de regle contenant une majuscule n'est pas dans Pfinal
Dans l'exemple, on peut retirer la regle Q -> RQ + bQ
=====================================================
1.2 La reduction

*Algo descendant

P'0 = {S}

rep jsq invariance

     P'i = P'i-1 Un{U € V, tel que U figure dans un membre droit qcq au moins une fois}

frep

*exemple : 
S -> aT + bU + KL
K -> aW + PUC
C -> a
T -> bU
U -> 1
W -> aW +1
R -> a + RM
M -> aMM + b
L -> LL + a
P -> 1

application de l'algorithme
P'O
S || TUKL || WPC ||
{   P'1   }
{       P'2      }

P'2 = P'final

*nettoyage :
     on enleve toute regle dont le membre gauche n'est pas dans P'final
====================================================
1.3 Conclusion

bilan : G ne contient que des éléments du VocabulR qui sont productifs depuis S
G est connexe!!

------------------------------------
2 élimination des productions vides
==================================
2.1 Définition

*une production vide est une regle qui contient en membre droit exactement le mot vide

*production vide directe : P -> 1

*production vide indirecte : 
P -> aP + Q + R
Q -> RT + W
W-> WW + LM        ==> 1 € L(W)
L -> LL + 1         ==> 1 € L(L)   
M -> M + a + 1      ==> 1 € L(M)


___________________
Cours du 16/12/2013
_____________________
Grammaires Attribuées
-------------------------------------
1 Garder les grammaires algébriques ?
==============
1.1 Complexité

Théorème C.Y.K
Coke/Younger/Kasami
=> la complexité de la reconnaissance d'un mot de n lettres est de o(n³)
Le temps de calcul est proportionnel au carré de n

===================================
1.2 Limitation avec (a^n)(b^n)(c^n)

on montre que (a^n)(b^n)(c^n) ne peut etre reconnu
on prend une démonstration plus simple

a^n b^n reconnu par 1 gramR (1 AEF)
-> On a une entrée, x boucles, et une sortie
Le seul automate utilisable est un automate à pile.

-----------
2 Attributs
========
2.1 Idée

On souhaite reconnaitre (a^n)(b^n)(c^n)

aSbc => faux :> (a^n)(b^n)c⁺, n > 0

S -> TU
T -> aTb + ab
U -> cU + c

(a^n)(b^n)(c^p)  => On ne veut accepter que quand p = n

1 attribut : 1 valeur attachée à un nom terminal
===========
2.2 Exemple

S  ->  T(a) U(c).(a=c)
T(u)->  a T(t).b . (u = t+1)         ## t le nombre de ab remonté par ce T
T(t)->  a b.(t = 1)
U(z)->  c U(y) . (z = y + 1)          ##y le nombre de c remonté par cet U là.
U(x)->  c(x = 1)

On compte le nombre de ab et c qu'on "remonte", et on les compare. On ne reconnait la gramR qu'en cas d'égalité

=====================
2.3 Types d'attributs

-Types majeurs : attributs syntétisés (ascendant)
                 attributs hérités (descendant)

Des informations (ascendantes ou descendantes) migrent dans la gramR
================================
2.4 Notations pour les attributs

A(1) -> a
B(n+2) -> A(n)

*vallex : valeur lexicale
D -> "0" + "1" + "2" + "3" +"4"+ "5" + "6" + "7" + "8" + "9"
On redécoupe en dix regles
D(0) -> "0"
D(1) -> "1"
|    |    |
|    |    |
D(9) -> "9"

=> D(vallex) -> "0" + "" etc
----------------------
3 points de génération
========
3.1 Rôle

1 pt de génération est un code éxécutable
ainsi S -> A(a).(a == 5)
a == 5 est un appel de fonction qui renvoie un booléen exploité comme le booléen bA par l'appel de A
On dit que a == 5 filtre/bride le langage afin de reconnaitre moins que prévu (un sous ensemble du langage)

T -> P(y, z).bCarré(y, z)

fcnt bCarré(int y, z)bool
     bool bt
     bt := (z = y²)
     retourner(bt)
finfcnt

Cette regles est toujours utilisé ; si absence de retour, on suppose que la valeur de vérité est "vrai"
===============================
3.2 Place des pts de génération

* ne peut pas etre décidé/connu à priori
* ajouter d'abord les attributs
* se demander ensuite quel est le meilleur endroit pour exploiter les attributs
* placer les pts de génération en conséquence

ex : L = { m € A*, m = a^n, n est un carré, n > 0}
L' = {m € A* m = a⁺}

S -> aS + a
S(n+1) -> a  .  S(n).bCarré(n+1)
S(1) -> a

==> Mauvaise idée car à cause de la récursivité, on teste si n+1 est un carré à chaque a ajouté (ce qui foire au premier a)

Meilleur et correct : 
S -> T(p).bCarré(p)
T(n+1)  -> a  T(n)
T(1)   ->  a

C'est très souvent interresant de placer un point de génération à la fin, car il a alors accès à toutes les données

On propose de compter les a et les b

S -> T(x, y) U(z).(x == y == z)
T ->(M + 1, n +1) -> aT(m, n)b
T(1, 1) -> ab
U(n+1) -> cU(n)
U(1)->  C

=======================
3.3 Ordres d'évaluation

la règle à retenir : l'évaluation des non terminaux doit pouvoir se faire de gauche à droite. Le compilateur fera après à son idée.

----------------
4 Applications :

-Réaliser des compilateurs
-reconnaitres des formes
-En ajoutant un attribut de temps, on peut réaliser des dessins animées, paramétrer l'affichage d'une formule de math/autre



